{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import init\n",
    "from torch.utils import model_zoo\n",
    "from torchvision.models import vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "# FCN 8s\n",
    "class fcn8s(nn.Module):\n",
    "    def __init__(self, n_classes=19, learned_billinear=True):\n",
    "        super(fcn8s, self).__init__()\n",
    "        self.learned_billinear = learned_billinear\n",
    "        self.n_classes = n_classes\n",
    "        self.loss = functools.partial(cross_entropy2d, size_average=False)\n",
    "\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n",
    "        )\n",
    "\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n",
    "        )\n",
    "\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n",
    "        )\n",
    "\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n",
    "        )\n",
    "\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv2d(512, 4096, 7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Conv2d(4096, 4096, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Conv2d(4096, self.n_classes, 1),\n",
    "        )\n",
    "\n",
    "        self.score_pool4 = nn.Conv2d(512, self.n_classes, 1)\n",
    "        self.score_pool3 = nn.Conv2d(256, self.n_classes, 1)\n",
    "\n",
    "        if self.learned_billinear:\n",
    "            self.upscore2 = nn.ConvTranspose2d(\n",
    "                self.n_classes, self.n_classes, 4, stride=2, bias=False\n",
    "            )\n",
    "            self.upscore4 = nn.ConvTranspose2d(\n",
    "                self.n_classes, self.n_classes, 4, stride=2, bias=False\n",
    "            )\n",
    "            self.upscore8 = nn.ConvTranspose2d(\n",
    "                self.n_classes, self.n_classes, 16, stride=8, bias=False\n",
    "            )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                m.weight.data.copy_(\n",
    "                    get_upsampling_weight(m.in_channels, m.out_channels, m.kernel_size[0])\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv_block1(x)\n",
    "        conv2 = self.conv_block2(conv1)\n",
    "        conv3 = self.conv_block3(conv2)\n",
    "        conv4 = self.conv_block4(conv3)\n",
    "        conv5 = self.conv_block5(conv4)\n",
    "\n",
    "        score = self.classifier(conv5)\n",
    "\n",
    "        if self.learned_billinear:\n",
    "            upscore2 = self.upscore2(score)\n",
    "            score_pool4c = self.score_pool4(conv4)[\n",
    "                :, :, 5 : 5 + upscore2.size()[2], 5 : 5 + upscore2.size()[3]\n",
    "            ]\n",
    "            upscore_pool4 = self.upscore4(upscore2 + score_pool4c)\n",
    "\n",
    "            score_pool3c = self.score_pool3(conv3)[\n",
    "                :, :, 9 : 9 + upscore_pool4.size()[2], 9 : 9 + upscore_pool4.size()[3]\n",
    "            ]\n",
    "\n",
    "            out = self.upscore8(score_pool3c + upscore_pool4)[\n",
    "                :, :, 31 : 31 + x.size()[2], 31 : 31 + x.size()[3]\n",
    "            ]\n",
    "            return out.contiguous()\n",
    "\n",
    "        else:\n",
    "            score_pool4 = self.score_pool4(conv4)\n",
    "            score_pool3 = self.score_pool3(conv3)\n",
    "            score = F.upsample(score, score_pool4.size()[2:])\n",
    "            score += score_pool4\n",
    "            score = F.upsample(score, score_pool3.size()[2:])\n",
    "            score += score_pool3\n",
    "            out = F.upsample(score, x.size()[2:])\n",
    "\n",
    "        return out\n",
    "\n",
    "    def init_vgg16_params(self, vgg16, copy_fc8=True):\n",
    "        blocks = [\n",
    "            self.conv_block1,\n",
    "            self.conv_block2,\n",
    "            self.conv_block3,\n",
    "            self.conv_block4,\n",
    "            self.conv_block5,\n",
    "        ]\n",
    "\n",
    "        ranges = [[0, 4], [5, 9], [10, 16], [17, 23], [24, 29]]\n",
    "        features = list(vgg16.features.children())\n",
    "\n",
    "        for idx, conv_block in enumerate(blocks):\n",
    "            for l1, l2 in zip(features[ranges[idx][0] : ranges[idx][1]], conv_block):\n",
    "                if isinstance(l1, nn.Conv2d) and isinstance(l2, nn.Conv2d):\n",
    "                    assert l1.weight.size() == l2.weight.size()\n",
    "                    assert l1.bias.size() == l2.bias.size()\n",
    "                    l2.weight.data = l1.weight.data\n",
    "                    l2.bias.data = l1.bias.data\n",
    "        for i1, i2 in zip([0, 3], [0, 3]):\n",
    "            l1 = vgg16.classifier[i1]\n",
    "            l2 = self.classifier[i2]\n",
    "            l2.weight.data = l1.weight.data.view(l2.weight.size())\n",
    "            l2.bias.data = l1.bias.data.view(l2.bias.size())\n",
    "        n_class = self.classifier[6].weight.size()[0]\n",
    "        if copy_fc8:\n",
    "            l1 = vgg16.classifier[6]\n",
    "            l2 = self.classifier[6]\n",
    "            l2.weight.data = l1.weight.data[:n_class, :].view(l2.weight.size())\n",
    "            l2.bias.data = l1.bias.data[:n_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_upsample_filter(size):\n",
    "#     \"\"\"Make a 2D bilinear kernel suitable for upsampling\"\"\"\n",
    "#     factor = (size + 1) // 2\n",
    "#     if size % 2 == 1:\n",
    "#         center = factor - 1\n",
    "#     else:\n",
    "#         center = factor - 0.5\n",
    "#     og = np.ogrid[:size, :size]\n",
    "#     filter = (1 - abs(og[0] - center) / factor) * \\\n",
    "#              (1 - abs(og[1] - center) / factor)\n",
    "#     return torch.from_numpy(filter).float()\n",
    "\n",
    "\n",
    "# class Bilinear(nn.Module):\n",
    "\n",
    "#     def __init__(self, factor, num_channels):\n",
    "#         super(Bilinear, self).__init__()\n",
    "#         self.factor = factor\n",
    "#         filter = get_upsample_filter(factor * 2)\n",
    "#         w = torch.zeros(num_channels, num_channels, factor * 2, factor * 2)\n",
    "#         for i in range(num_channels):\n",
    "#             w[i, i] = filter\n",
    "#         self.register_buffer('w', w)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return F.conv_transpose2d(x, Variable(self.w), stride=self.factor)\n",
    "\n",
    "\n",
    "# #@register_model('fcn8s')\n",
    "# class VGG16_FCN8s(nn.Module):\n",
    "\n",
    "#     transform = torchvision.transforms.Compose([\n",
    "#         torchvision.transforms.ToTensor(),\n",
    "#         torchvision.transforms.Normalize(\n",
    "#             mean=[0.485, 0.456, 0.406],\n",
    "#             std=[0.229, 0.224, 0.225]),\n",
    "#         ])\n",
    "\n",
    "#     def __init__(self, num_cls=19, pretrained=True, weights_init=None, \n",
    "#             output_last_ft=False):\n",
    "#         super(VGG16_FCN8s, self).__init__()\n",
    "#         self.output_last_ft = output_last_ft\n",
    "#         self.vgg = make_layers(vgg.cfg['D'])\n",
    "#         self.vgg_head = nn.Sequential(\n",
    "#             nn.Conv2d(512, 4096, 7),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout2d(p=0.5),\n",
    "#             nn.Conv2d(4096, 4096, 1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout2d(p=0.5),\n",
    "#             nn.Conv2d(4096, num_cls, 1)\n",
    "#             )\n",
    "#         self.upscore2 = self.upscore_pool4 = Bilinear(2, num_cls)\n",
    "#         self.upscore8 = Bilinear(8, num_cls)\n",
    "#         self.score_pool4 = nn.Conv2d(512, num_cls, 1)\n",
    "#         for param in self.score_pool4.parameters():\n",
    "#             init.constant(param, 0)\n",
    "#         self.score_pool3 = nn.Conv2d(256, num_cls, 1)\n",
    "#         for param in self.score_pool3.parameters():\n",
    "#             init.constant(param, 0)\n",
    "        \n",
    "#         if pretrained:\n",
    "#             if weights_init is not None:\n",
    "#                 self.load_weights(torch.load(weights_init))\n",
    "#             else:\n",
    "#                 self.load_base_weights()\n",
    " \n",
    "#     def load_base_vgg(self, weights_state_dict):\n",
    "#         vgg_state_dict = self.get_dict_by_prefix(weights_state_dict, 'vgg.')\n",
    "#         self.vgg.load_state_dict(vgg_state_dict)\n",
    "     \n",
    "#     def load_vgg_head(self, weights_state_dict):\n",
    "#         vgg_head_state_dict = self.get_dict_by_prefix(weights_state_dict, 'vgg_head.') \n",
    "#         self.vgg_head.load_state_dict(vgg_head_state_dict)\n",
    "    \n",
    "#     def get_dict_by_prefix(self, weights_state_dict, prefix):\n",
    "#         return {k[len(prefix):]: v \n",
    "#                 for k,v in weights_state_dict.items()\n",
    "#                 if k.startswith(prefix)}\n",
    "\n",
    "\n",
    "#     def load_weights(self, weights_state_dict):\n",
    "#         self.load_base_vgg(weights_state_dict)\n",
    "#         self.load_vgg_head(weights_state_dict)\n",
    "\n",
    "#     def split_vgg_head(self):\n",
    "#         self.classifier = list(self.vgg_head.children())[-1]\n",
    "#         self.vgg_head_feat = nn.Sequential(*list(self.vgg_head.children())[:-1])\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         input = x\n",
    "#         x = F.pad(x, (99, 99, 99, 99), mode='constant', value=0)\n",
    "#         intermediates = {}\n",
    "#         fts_to_save = {16: 'pool3', 23: 'pool4'}\n",
    "#         for i, module in enumerate(self.vgg):\n",
    "#             x = module(x)\n",
    "#             if i in fts_to_save:\n",
    "#                 intermediates[fts_to_save[i]] = x\n",
    "       \n",
    "#         ft_to_save = 5 # Dropout before classifier\n",
    "#         last_ft = {}\n",
    "#         for i, module in enumerate(self.vgg_head):\n",
    "#             x = module(x)\n",
    "#             if i == ft_to_save:\n",
    "#                 last_ft = x      \n",
    "        \n",
    "#         _, _, h, w = x.size()\n",
    "#         upscore2 = self.upscore2(x)\n",
    "#         pool4 = intermediates['pool4']\n",
    "#         score_pool4 = self.score_pool4(0.01 * pool4)\n",
    "#         score_pool4c = _crop(score_pool4, upscore2, offset=5)\n",
    "#         fuse_pool4 = upscore2 + score_pool4c\n",
    "#         upscore_pool4 = self.upscore_pool4(fuse_pool4)\n",
    "#         pool3 = intermediates['pool3']\n",
    "#         score_pool3 = self.score_pool3(0.0001 * pool3)\n",
    "#         score_pool3c = _crop(score_pool3, upscore_pool4, offset=9)\n",
    "#         fuse_pool3 = upscore_pool4 + score_pool3c\n",
    "#         upscore8 = self.upscore8(fuse_pool3)\n",
    "#         score = _crop(upscore8, input, offset=31)\n",
    "#         if self.output_last_ft: \n",
    "#             return score, last_ft\n",
    "#         else:\n",
    "#             return score\n",
    "\n",
    "\n",
    "#     def load_base_weights(self):\n",
    "#         \"\"\"This is complicated because we converted the base model to be fully\n",
    "#         convolutional, so some surgery needs to happen here.\"\"\"\n",
    "#         base_state_dict = model_zoo.load_url(vgg.model_urls['vgg16'])\n",
    "#         vgg_state_dict = {k[len('features.'):]: v\n",
    "#                           for k, v in base_state_dict.items()\n",
    "#                           if k.startswith('features.')}\n",
    "#         self.vgg.load_state_dict(vgg_state_dict)\n",
    "#         vgg_head_params = self.vgg_head.parameters()\n",
    "#         for k, v in base_state_dict.items():\n",
    "#             if not k.startswith('classifier.'):\n",
    "#                 continue\n",
    "#             if k.startswith('classifier.6.'):\n",
    "#                 # skip final classifier output\n",
    "#                 continue\n",
    "#             vgg_head_param = next(vgg_head_params)\n",
    "#             vgg_head_param.data = v.view(vgg_head_param.size())\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def make_layers(cfg, batch_norm=False):\n",
    "#     \"\"\"This is almost verbatim from torchvision.models.vgg, except that the\n",
    "#     MaxPool2d modules are configured with ceil_mode=True.\n",
    "#     \"\"\"\n",
    "#     layers = []\n",
    "#     in_channels = 3\n",
    "#     for v in cfg:\n",
    "#         if v == 'M':\n",
    "#             layers.append(nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True))\n",
    "#         else:\n",
    "#             conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "#             modules = [conv2d, nn.ReLU(inplace=True)]\n",
    "#             if batch_norm:\n",
    "#                 modules.insert(1, nn.BatchNorm2d(v))\n",
    "#             layers.extend(modules)\n",
    "#             in_channels = v\n",
    "#     return nn.Sequential(*layers)\n",
    "\n",
    "# def _crop(input, shape, offset=0):\n",
    "#     _, _, h, w = shape.size()\n",
    "#     return input[:, :, offset:offset + h, offset:offset + w].contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy2d(input, target, weight=None, size_average=True):\n",
    "    n, c, h, w = input.size()\n",
    "    nt, ht, wt = target.size()\n",
    "\n",
    "    # Handle inconsistent size between input and target\n",
    "    if h != ht and w != wt:  # upsample labels\n",
    "        input = F.interpolate(input, size=(ht, wt), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "    input = input.transpose(1, 2).transpose(2, 3).contiguous().view(-1, c)\n",
    "    target = target.view(-1)\n",
    "    loss = F.cross_entropy(\n",
    "        input, target, weight=weight, size_average=size_average, ignore_index=250\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_upsampling_weight(in_channels, out_channels, kernel_size):\n",
    "    \"\"\"Make a 2D bilinear kernel suitable for upsampling\"\"\"\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size), dtype=np.float64)\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return torch.from_numpy(weight).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = fcn8s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = torch.Tensor(5, 3, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = tmp.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = net(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 19, 256, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/kernel/__main__.py:56: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/kernel/__main__.py:59: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    }
   ],
   "source": [
    "net = VGG16_FCN8s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = torch.Tensor(5, 3, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = tmp.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = net(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-6.1265e-03, -6.4581e-03, -6.8073e-03,  ..., -3.5109e-02,\n",
       "           -3.5082e-02, -3.5056e-02],\n",
       "          [-6.3829e-03, -6.7290e-03, -7.0939e-03,  ..., -3.6663e-02,\n",
       "           -3.6633e-02, -3.6603e-02],\n",
       "          [-6.5814e-03, -6.9395e-03, -7.3180e-03,  ..., -3.7972e-02,\n",
       "           -3.7935e-02, -3.7898e-02],\n",
       "          ...,\n",
       "          [ 1.7765e-03,  1.6606e-03,  1.3378e-03,  ..., -3.5807e-02,\n",
       "           -3.4817e-02, -3.3827e-02],\n",
       "          [ 2.8265e-03,  2.7562e-03,  2.4706e-03,  ..., -3.4297e-02,\n",
       "           -3.3303e-02, -3.2309e-02],\n",
       "          [ 3.8765e-03,  3.8517e-03,  3.6034e-03,  ..., -3.2787e-02,\n",
       "           -3.1789e-02, -3.0791e-02]],\n",
       "\n",
       "         [[-1.4857e-02, -1.5494e-02, -1.6006e-02,  ..., -1.9586e-02,\n",
       "           -2.0184e-02, -2.0781e-02],\n",
       "          [-1.5364e-02, -1.6022e-02, -1.6551e-02,  ..., -2.0192e-02,\n",
       "           -2.0814e-02, -2.1437e-02],\n",
       "          [-1.5616e-02, -1.6285e-02, -1.6822e-02,  ..., -2.0399e-02,\n",
       "           -2.1041e-02, -2.1683e-02],\n",
       "          ...,\n",
       "          [ 3.5960e-03,  3.8269e-03,  4.1042e-03,  ...,  1.8086e-02,\n",
       "            1.7612e-02,  1.7138e-02],\n",
       "          [ 3.7108e-03,  3.9453e-03,  4.2240e-03,  ...,  1.7871e-02,\n",
       "            1.7393e-02,  1.6916e-02],\n",
       "          [ 3.8255e-03,  4.0637e-03,  4.3438e-03,  ...,  1.7655e-02,\n",
       "            1.7174e-02,  1.6693e-02]],\n",
       "\n",
       "         [[ 3.1857e-02,  3.3250e-02,  3.4401e-02,  ...,  3.9160e-02,\n",
       "            3.9267e-02,  3.9373e-02],\n",
       "          [ 3.3151e-02,  3.4600e-02,  3.5798e-02,  ...,  4.0748e-02,\n",
       "            4.0859e-02,  4.0971e-02],\n",
       "          [ 3.4106e-02,  3.5596e-02,  3.6828e-02,  ...,  4.1914e-02,\n",
       "            4.2030e-02,  4.2147e-02],\n",
       "          ...,\n",
       "          [ 3.0017e-03,  3.1073e-03,  3.1646e-03,  ..., -2.9524e-03,\n",
       "           -2.6477e-03, -2.3430e-03],\n",
       "          [ 2.6759e-03,  2.7672e-03,  2.8124e-03,  ..., -3.8775e-03,\n",
       "           -3.5730e-03, -3.2686e-03],\n",
       "          [ 2.3502e-03,  2.4270e-03,  2.4602e-03,  ..., -4.8026e-03,\n",
       "           -4.4984e-03, -4.1941e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.0443e-02,  3.1802e-02,  3.2956e-02,  ...,  4.5612e-02,\n",
       "            4.5378e-02,  4.5144e-02],\n",
       "          [ 3.1745e-02,  3.3161e-02,  3.4365e-02,  ...,  4.7499e-02,\n",
       "            4.7257e-02,  4.7015e-02],\n",
       "          [ 3.2788e-02,  3.4249e-02,  3.5491e-02,  ...,  4.8933e-02,\n",
       "            4.8687e-02,  4.8441e-02],\n",
       "          ...,\n",
       "          [ 2.9971e-02,  3.1200e-02,  3.2122e-02,  ...,  2.9639e-02,\n",
       "            2.9910e-02,  3.0180e-02],\n",
       "          [ 3.0456e-02,  3.1710e-02,  3.2654e-02,  ...,  3.0908e-02,\n",
       "            3.1171e-02,  3.1434e-02],\n",
       "          [ 3.0942e-02,  3.2219e-02,  3.3186e-02,  ...,  3.2177e-02,\n",
       "            3.2433e-02,  3.2688e-02]],\n",
       "\n",
       "         [[ 7.0440e-02,  7.3596e-02,  7.6296e-02,  ...,  1.1211e-01,\n",
       "            1.1234e-01,  1.1258e-01],\n",
       "          [ 7.3432e-02,  7.6721e-02,  7.9535e-02,  ...,  1.1679e-01,\n",
       "            1.1704e-01,  1.1728e-01],\n",
       "          [ 7.5804e-02,  7.9198e-02,  8.2099e-02,  ...,  1.2040e-01,\n",
       "            1.2066e-01,  1.2092e-01],\n",
       "          ...,\n",
       "          [ 7.3257e-02,  7.6366e-02,  7.8828e-02,  ...,  9.9604e-02,\n",
       "            1.0078e-01,  1.0196e-01],\n",
       "          [ 7.4026e-02,  7.7171e-02,  7.9666e-02,  ...,  1.0106e-01,\n",
       "            1.0225e-01,  1.0344e-01],\n",
       "          [ 7.4796e-02,  7.7977e-02,  8.0503e-02,  ...,  1.0252e-01,\n",
       "            1.0372e-01,  1.0491e-01]],\n",
       "\n",
       "         [[-9.9144e-02, -1.0339e-01, -1.0678e-01,  ..., -1.1848e-01,\n",
       "           -1.1941e-01, -1.2034e-01],\n",
       "          [-1.0339e-01, -1.0782e-01, -1.1136e-01,  ..., -1.2351e-01,\n",
       "           -1.2448e-01, -1.2545e-01],\n",
       "          [-1.0681e-01, -1.1137e-01, -1.1503e-01,  ..., -1.2749e-01,\n",
       "           -1.2849e-01, -1.2949e-01],\n",
       "          ...,\n",
       "          [-1.3141e-01, -1.3700e-01, -1.4145e-01,  ..., -1.4814e-01,\n",
       "           -1.4928e-01, -1.5041e-01],\n",
       "          [-1.3322e-01, -1.3889e-01, -1.4341e-01,  ..., -1.5064e-01,\n",
       "           -1.5177e-01, -1.5290e-01],\n",
       "          [-1.3503e-01, -1.4078e-01, -1.4537e-01,  ..., -1.5313e-01,\n",
       "           -1.5426e-01, -1.5538e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.9567e-02, -4.1314e-02, -4.2779e-02,  ..., -8.2476e-02,\n",
       "           -8.3031e-02, -8.3586e-02],\n",
       "          [-4.1271e-02, -4.3094e-02, -4.4623e-02,  ..., -8.6145e-02,\n",
       "           -8.6720e-02, -8.7295e-02],\n",
       "          [-4.2649e-02, -4.4534e-02, -4.6117e-02,  ..., -8.9252e-02,\n",
       "           -8.9839e-02, -9.0425e-02],\n",
       "          ...,\n",
       "          [-3.7915e-02, -3.9736e-02, -4.1434e-02,  ..., -1.0343e-01,\n",
       "           -1.0312e-01, -1.0280e-01],\n",
       "          [-3.7705e-02, -3.9515e-02, -4.1200e-02,  ..., -1.0250e-01,\n",
       "           -1.0219e-01, -1.0187e-01],\n",
       "          [-3.7496e-02, -3.9294e-02, -4.0967e-02,  ..., -1.0157e-01,\n",
       "           -1.0126e-01, -1.0095e-01]],\n",
       "\n",
       "         [[-3.6853e-02, -3.8468e-02, -3.9809e-02,  ..., -4.9876e-02,\n",
       "           -5.0468e-02, -5.1059e-02],\n",
       "          [-3.8471e-02, -4.0158e-02, -4.1558e-02,  ..., -5.2147e-02,\n",
       "           -5.2767e-02, -5.3386e-02],\n",
       "          [-3.9819e-02, -4.1565e-02, -4.3014e-02,  ..., -5.4133e-02,\n",
       "           -5.4777e-02, -5.5422e-02],\n",
       "          ...,\n",
       "          [-4.8453e-02, -5.0607e-02, -5.2430e-02,  ..., -9.7718e-02,\n",
       "           -9.8910e-02, -1.0010e-01],\n",
       "          [-4.8840e-02, -5.1011e-02, -5.2847e-02,  ..., -9.8693e-02,\n",
       "           -9.9887e-02, -1.0108e-01],\n",
       "          [-4.9227e-02, -5.1415e-02, -5.3264e-02,  ..., -9.9667e-02,\n",
       "           -1.0086e-01, -1.0206e-01]],\n",
       "\n",
       "         [[-2.5739e-02, -2.6872e-02, -2.7818e-02,  ..., -3.1227e-02,\n",
       "           -3.1154e-02, -3.1081e-02],\n",
       "          [-2.6769e-02, -2.7948e-02, -2.8931e-02,  ..., -3.2390e-02,\n",
       "           -3.2316e-02, -3.2242e-02],\n",
       "          [-2.7510e-02, -2.8721e-02, -2.9730e-02,  ..., -3.3112e-02,\n",
       "           -3.3041e-02, -3.2970e-02],\n",
       "          ...,\n",
       "          [-3.1251e-02, -3.2559e-02, -3.3573e-02,  ..., -3.3848e-02,\n",
       "           -3.4767e-02, -3.5686e-02],\n",
       "          [-3.2148e-02, -3.3500e-02, -3.4554e-02,  ..., -3.6245e-02,\n",
       "           -3.7169e-02, -3.8094e-02],\n",
       "          [-3.3045e-02, -3.4440e-02, -3.5535e-02,  ..., -3.8641e-02,\n",
       "           -3.9571e-02, -4.0502e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.0192e-02, -3.1529e-02, -3.2656e-02,  ..., -4.0851e-02,\n",
       "           -4.0458e-02, -4.0065e-02],\n",
       "          [-3.1456e-02, -3.2851e-02, -3.4026e-02,  ..., -4.2642e-02,\n",
       "           -4.2228e-02, -4.1813e-02],\n",
       "          [-3.2436e-02, -3.3876e-02, -3.5091e-02,  ..., -4.4128e-02,\n",
       "           -4.3692e-02, -4.3256e-02],\n",
       "          ...,\n",
       "          [-3.9580e-02, -4.1469e-02, -4.3217e-02,  ..., -6.3822e-02,\n",
       "           -6.2657e-02, -6.1492e-02],\n",
       "          [-3.9933e-02, -4.1832e-02, -4.3582e-02,  ..., -6.3464e-02,\n",
       "           -6.2315e-02, -6.1166e-02],\n",
       "          [-4.0286e-02, -4.2195e-02, -4.3946e-02,  ..., -6.3105e-02,\n",
       "           -6.1973e-02, -6.0841e-02]],\n",
       "\n",
       "         [[ 1.2506e-02,  1.3022e-02,  1.3413e-02,  ...,  2.1679e-03,\n",
       "            2.3561e-03,  2.5443e-03],\n",
       "          [ 1.3036e-02,  1.3574e-02,  1.3981e-02,  ...,  2.2798e-03,\n",
       "            2.4771e-03,  2.6745e-03],\n",
       "          [ 1.3455e-02,  1.4010e-02,  1.4429e-02,  ...,  2.3924e-03,\n",
       "            2.5984e-03,  2.8044e-03],\n",
       "          ...,\n",
       "          [ 2.3938e-02,  2.4967e-02,  2.5798e-02,  ...,  3.9444e-02,\n",
       "            3.9749e-02,  4.0054e-02],\n",
       "          [ 2.4823e-02,  2.5894e-02,  2.6763e-02,  ...,  4.1521e-02,\n",
       "            4.1834e-02,  4.2146e-02],\n",
       "          [ 2.5708e-02,  2.6820e-02,  2.7728e-02,  ...,  4.3598e-02,\n",
       "            4.3918e-02,  4.4238e-02]],\n",
       "\n",
       "         [[-8.8450e-02, -9.2282e-02, -9.5411e-02,  ..., -1.2116e-01,\n",
       "           -1.2154e-01, -1.2192e-01],\n",
       "          [-9.2409e-02, -9.6412e-02, -9.9680e-02,  ..., -1.2652e-01,\n",
       "           -1.2692e-01, -1.2732e-01],\n",
       "          [-9.5790e-02, -9.9940e-02, -1.0333e-01,  ..., -1.3103e-01,\n",
       "           -1.3145e-01, -1.3186e-01],\n",
       "          ...,\n",
       "          [-1.3551e-01, -1.4134e-01, -1.4605e-01,  ..., -1.8977e-01,\n",
       "           -1.9056e-01, -1.9135e-01],\n",
       "          [-1.3611e-01, -1.4196e-01, -1.4669e-01,  ..., -1.9115e-01,\n",
       "           -1.9193e-01, -1.9271e-01],\n",
       "          [-1.3670e-01, -1.4259e-01, -1.4734e-01,  ..., -1.9254e-01,\n",
       "           -1.9331e-01, -1.9408e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.6496e-02,  2.7608e-02,  2.8475e-02,  ...,  1.8365e-02,\n",
       "            1.8614e-02,  1.8863e-02],\n",
       "          [ 2.7451e-02,  2.8602e-02,  2.9498e-02,  ...,  1.8666e-02,\n",
       "            1.8925e-02,  1.9183e-02],\n",
       "          [ 2.8003e-02,  2.9175e-02,  3.0083e-02,  ...,  1.8326e-02,\n",
       "            1.8591e-02,  1.8856e-02],\n",
       "          ...,\n",
       "          [-4.7595e-03, -5.1996e-03, -5.8359e-03,  ..., -7.1347e-02,\n",
       "           -7.1040e-02, -7.0734e-02],\n",
       "          [-3.5574e-03, -3.9422e-03, -4.5294e-03,  ..., -6.8883e-02,\n",
       "           -6.8575e-02, -6.8266e-02],\n",
       "          [-2.3553e-03, -2.6848e-03, -3.2229e-03,  ..., -6.6420e-02,\n",
       "           -6.6109e-02, -6.5798e-02]],\n",
       "\n",
       "         [[ 5.4273e-02,  5.6667e-02,  5.8673e-02,  ...,  7.3726e-02,\n",
       "            7.3479e-02,  7.3232e-02],\n",
       "          [ 5.6572e-02,  5.9068e-02,  6.1160e-02,  ...,  7.6760e-02,\n",
       "            7.6498e-02,  7.6237e-02],\n",
       "          [ 5.8387e-02,  6.0964e-02,  6.3123e-02,  ...,  7.9047e-02,\n",
       "            7.8769e-02,  7.8491e-02],\n",
       "          ...,\n",
       "          [ 6.7584e-02,  7.0617e-02,  7.3216e-02,  ...,  7.9541e-02,\n",
       "            7.8234e-02,  7.6928e-02],\n",
       "          [ 6.8883e-02,  7.1973e-02,  7.4619e-02,  ...,  8.1684e-02,\n",
       "            8.0373e-02,  7.9062e-02],\n",
       "          [ 7.0182e-02,  7.3329e-02,  7.6023e-02,  ...,  8.3828e-02,\n",
       "            8.2512e-02,  8.1195e-02]],\n",
       "\n",
       "         [[ 2.6613e-02,  2.7762e-02,  2.8695e-02,  ...,  3.8431e-02,\n",
       "            3.8750e-02,  3.9070e-02],\n",
       "          [ 2.7781e-02,  2.8981e-02,  2.9956e-02,  ...,  4.0207e-02,\n",
       "            4.0538e-02,  4.0869e-02],\n",
       "          [ 2.8752e-02,  2.9995e-02,  3.1006e-02,  ...,  4.1789e-02,\n",
       "            4.2126e-02,  4.2462e-02],\n",
       "          ...,\n",
       "          [ 7.0862e-03,  7.4550e-03,  7.8292e-03,  ...,  3.4771e-02,\n",
       "            3.4909e-02,  3.5047e-02],\n",
       "          [ 6.8782e-03,  7.2347e-03,  7.5951e-03,  ...,  3.4176e-02,\n",
       "            3.4336e-02,  3.4496e-02],\n",
       "          [ 6.6701e-03,  7.0144e-03,  7.3610e-03,  ...,  3.3581e-02,\n",
       "            3.3763e-02,  3.3946e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.5165e-02, -3.6608e-02, -3.7689e-02,  ..., -3.4961e-02,\n",
       "           -3.5482e-02, -3.6002e-02],\n",
       "          [-3.6568e-02, -3.8068e-02, -3.9194e-02,  ..., -3.6421e-02,\n",
       "           -3.6962e-02, -3.7504e-02],\n",
       "          [-3.7570e-02, -3.9113e-02, -4.0271e-02,  ..., -3.7547e-02,\n",
       "           -3.8103e-02, -3.8660e-02],\n",
       "          ...,\n",
       "          [-2.8117e-02, -2.9362e-02, -3.0411e-02,  ..., -4.4982e-02,\n",
       "           -4.5264e-02, -4.5547e-02],\n",
       "          [-2.9264e-02, -3.0556e-02, -3.1639e-02,  ..., -4.5777e-02,\n",
       "           -4.6065e-02, -4.6354e-02],\n",
       "          [-3.0410e-02, -3.1749e-02, -3.2866e-02,  ..., -4.6571e-02,\n",
       "           -4.6867e-02, -4.7162e-02]],\n",
       "\n",
       "         [[ 2.3682e-02,  2.4722e-02,  2.5588e-02,  ...,  2.9662e-02,\n",
       "            2.9679e-02,  2.9696e-02],\n",
       "          [ 2.4685e-02,  2.5769e-02,  2.6670e-02,  ...,  3.0807e-02,\n",
       "            3.0826e-02,  3.0844e-02],\n",
       "          [ 2.5478e-02,  2.6595e-02,  2.7523e-02,  ...,  3.1577e-02,\n",
       "            3.1597e-02,  3.1618e-02],\n",
       "          ...,\n",
       "          [ 5.4805e-02,  5.7111e-02,  5.8913e-02,  ...,  5.8683e-02,\n",
       "            5.9205e-02,  5.9727e-02],\n",
       "          [ 5.6289e-02,  5.8662e-02,  6.0521e-02,  ...,  6.1619e-02,\n",
       "            6.2147e-02,  6.2675e-02],\n",
       "          [ 5.7773e-02,  6.0213e-02,  6.2130e-02,  ...,  6.4555e-02,\n",
       "            6.5089e-02,  6.5622e-02]],\n",
       "\n",
       "         [[-6.0626e-02, -6.3250e-02, -6.5387e-02,  ..., -8.4157e-02,\n",
       "           -8.4674e-02, -8.5190e-02],\n",
       "          [-6.3213e-02, -6.5948e-02, -6.8177e-02,  ..., -8.7689e-02,\n",
       "           -8.8226e-02, -8.8763e-02],\n",
       "          [-6.5278e-02, -6.8102e-02, -7.0403e-02,  ..., -9.0435e-02,\n",
       "           -9.0988e-02, -9.1541e-02],\n",
       "          ...,\n",
       "          [-6.7116e-02, -7.0012e-02, -7.2362e-02,  ..., -8.8784e-02,\n",
       "           -8.9209e-02, -8.9634e-02],\n",
       "          [-6.7680e-02, -7.0602e-02, -7.2975e-02,  ..., -9.0547e-02,\n",
       "           -9.0978e-02, -9.1408e-02],\n",
       "          [-6.8245e-02, -7.1193e-02, -7.3589e-02,  ..., -9.2311e-02,\n",
       "           -9.2746e-02, -9.3182e-02]]],\n",
       "\n",
       "\n",
       "        [[[-8.5134e-03, -8.9809e-03, -9.4794e-03,  ..., -3.6341e-02,\n",
       "           -3.6588e-02, -3.6835e-02],\n",
       "          [-8.8531e-03, -9.3398e-03, -9.8592e-03,  ..., -3.7924e-02,\n",
       "           -3.8182e-02, -3.8440e-02],\n",
       "          [-9.0960e-03, -9.5970e-03, -1.0133e-02,  ..., -3.9226e-02,\n",
       "           -3.9493e-02, -3.9761e-02],\n",
       "          ...,\n",
       "          [ 1.4217e-02,  1.4671e-02,  1.4851e-02,  ..., -2.3596e-02,\n",
       "           -2.3928e-02, -2.4260e-02],\n",
       "          [ 1.4916e-02,  1.5402e-02,  1.5610e-02,  ..., -2.2505e-02,\n",
       "           -2.2850e-02, -2.3195e-02],\n",
       "          [ 1.5615e-02,  1.6133e-02,  1.6369e-02,  ..., -2.1415e-02,\n",
       "           -2.1773e-02, -2.2130e-02]],\n",
       "\n",
       "         [[ 1.5285e-02,  1.5933e-02,  1.6443e-02,  ...,  1.3617e-03,\n",
       "            7.2433e-04,  8.7016e-05],\n",
       "          [ 1.6179e-02,  1.6864e-02,  1.7406e-02,  ...,  1.8363e-03,\n",
       "            1.1725e-03,  5.0867e-04],\n",
       "          [ 1.7181e-02,  1.7911e-02,  1.8488e-02,  ...,  2.7158e-03,\n",
       "            2.0316e-03,  1.3475e-03],\n",
       "          ...,\n",
       "          [ 4.0938e-02,  4.2764e-02,  4.4315e-02,  ...,  5.1990e-02,\n",
       "            5.1212e-02,  5.0434e-02],\n",
       "          [ 4.0349e-02,  4.2146e-02,  4.3670e-02,  ...,  5.0720e-02,\n",
       "            4.9939e-02,  4.9157e-02],\n",
       "          [ 3.9759e-02,  4.1527e-02,  4.3025e-02,  ...,  4.9450e-02,\n",
       "            4.8665e-02,  4.7880e-02]],\n",
       "\n",
       "         [[ 3.0156e-02,  3.1517e-02,  3.2694e-02,  ...,  5.4703e-02,\n",
       "            5.5216e-02,  5.5728e-02],\n",
       "          [ 3.1316e-02,  3.2731e-02,  3.3954e-02,  ...,  5.6996e-02,\n",
       "            5.7532e-02,  5.8067e-02],\n",
       "          [ 3.2091e-02,  3.3541e-02,  3.4797e-02,  ...,  5.8777e-02,\n",
       "            5.9332e-02,  5.9888e-02],\n",
       "          ...,\n",
       "          [ 6.4681e-03,  6.9143e-03,  7.4749e-03,  ...,  4.9544e-02,\n",
       "            4.9745e-02,  4.9945e-02],\n",
       "          [ 6.7456e-03,  7.2038e-03,  7.7742e-03,  ...,  4.9414e-02,\n",
       "            4.9589e-02,  4.9764e-02],\n",
       "          [ 7.0232e-03,  7.4933e-03,  8.0735e-03,  ...,  4.9284e-02,\n",
       "            4.9433e-02,  4.9583e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.3784e-02,  7.6930e-02,  7.9437e-02,  ...,  9.0661e-02,\n",
       "            9.1207e-02,  9.1754e-02],\n",
       "          [ 7.6687e-02,  7.9956e-02,  8.2561e-02,  ...,  9.4122e-02,\n",
       "            9.4693e-02,  9.5265e-02],\n",
       "          [ 7.8710e-02,  8.2064e-02,  8.4734e-02,  ...,  9.6394e-02,\n",
       "            9.6988e-02,  9.7582e-02],\n",
       "          ...,\n",
       "          [ 1.7259e-02,  1.7796e-02,  1.7987e-02,  ..., -3.5241e-03,\n",
       "           -2.1244e-03, -7.2476e-04],\n",
       "          [ 1.7382e-02,  1.7928e-02,  1.8129e-02,  ..., -2.5899e-03,\n",
       "           -1.1929e-03,  2.0404e-04],\n",
       "          [ 1.7505e-02,  1.8059e-02,  1.8271e-02,  ..., -1.6558e-03,\n",
       "           -2.6148e-04,  1.1328e-03]],\n",
       "\n",
       "         [[ 1.0281e-01,  1.0725e-01,  1.1088e-01,  ...,  1.3776e-01,\n",
       "            1.3854e-01,  1.3932e-01],\n",
       "          [ 1.0723e-01,  1.1187e-01,  1.1565e-01,  ...,  1.4360e-01,\n",
       "            1.4441e-01,  1.4523e-01],\n",
       "          [ 1.1080e-01,  1.1559e-01,  1.1950e-01,  ...,  1.4820e-01,\n",
       "            1.4905e-01,  1.4990e-01],\n",
       "          ...,\n",
       "          [ 1.2643e-01,  1.3180e-01,  1.3605e-01,  ...,  1.6373e-01,\n",
       "            1.6543e-01,  1.6712e-01],\n",
       "          [ 1.2712e-01,  1.3252e-01,  1.3680e-01,  ...,  1.6566e-01,\n",
       "            1.6736e-01,  1.6906e-01],\n",
       "          [ 1.2781e-01,  1.3325e-01,  1.3756e-01,  ...,  1.6759e-01,\n",
       "            1.6929e-01,  1.7100e-01]],\n",
       "\n",
       "         [[-1.5612e-02, -1.6290e-02, -1.6846e-02,  ..., -2.7065e-02,\n",
       "           -2.7395e-02, -2.7725e-02],\n",
       "          [-1.6317e-02, -1.7025e-02, -1.7605e-02,  ..., -2.8160e-02,\n",
       "           -2.8504e-02, -2.8848e-02],\n",
       "          [-1.6926e-02, -1.7660e-02, -1.8261e-02,  ..., -2.8963e-02,\n",
       "           -2.9317e-02, -2.9671e-02],\n",
       "          ...,\n",
       "          [-3.2317e-02, -3.3693e-02, -3.4789e-02,  ..., -3.9253e-02,\n",
       "           -3.9504e-02, -3.9755e-02],\n",
       "          [-3.2641e-02, -3.4034e-02, -3.5147e-02,  ..., -4.0595e-02,\n",
       "           -4.0837e-02, -4.1078e-02],\n",
       "          [-3.2965e-02, -3.4375e-02, -3.5505e-02,  ..., -4.1937e-02,\n",
       "           -4.2169e-02, -4.2401e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 6.3826e-02,  6.6590e-02,  6.8844e-02,  ...,  7.5378e-02,\n",
       "            7.5544e-02,  7.5709e-02],\n",
       "          [ 6.6593e-02,  6.9476e-02,  7.1828e-02,  ...,  7.8547e-02,\n",
       "            7.8721e-02,  7.8895e-02],\n",
       "          [ 6.8854e-02,  7.1834e-02,  7.4264e-02,  ...,  8.1020e-02,\n",
       "            8.1203e-02,  8.1385e-02],\n",
       "          ...,\n",
       "          [ 7.6409e-02,  7.9529e-02,  8.1850e-02,  ...,  5.9019e-02,\n",
       "            6.0102e-02,  6.1184e-02],\n",
       "          [ 7.7319e-02,  8.0476e-02,  8.2824e-02,  ...,  5.9657e-02,\n",
       "            6.0774e-02,  6.1890e-02],\n",
       "          [ 7.8230e-02,  8.1423e-02,  8.3797e-02,  ...,  6.0295e-02,\n",
       "            6.1446e-02,  6.2596e-02]],\n",
       "\n",
       "         [[ 1.4102e-02,  1.4648e-02,  1.5019e-02,  ...,  7.2401e-03,\n",
       "            7.0641e-03,  6.8881e-03],\n",
       "          [ 1.4810e-02,  1.5385e-02,  1.5775e-02,  ...,  7.6694e-03,\n",
       "            7.4839e-03,  7.2984e-03],\n",
       "          [ 1.5503e-02,  1.6106e-02,  1.6516e-02,  ...,  8.1566e-03,\n",
       "            7.9611e-03,  7.7657e-03],\n",
       "          ...,\n",
       "          [ 2.8169e-02,  2.9352e-02,  3.0274e-02,  ...,  2.9030e-02,\n",
       "            2.8444e-02,  2.7859e-02],\n",
       "          [ 2.7558e-02,  2.8713e-02,  2.9610e-02,  ...,  2.8174e-02,\n",
       "            2.7603e-02,  2.7032e-02],\n",
       "          [ 2.6946e-02,  2.8074e-02,  2.8947e-02,  ...,  2.7318e-02,\n",
       "            2.6762e-02,  2.6206e-02]],\n",
       "\n",
       "         [[-4.5271e-02, -4.7112e-02, -4.8472e-02,  ..., -4.1273e-02,\n",
       "           -4.1858e-02, -4.2443e-02],\n",
       "          [-4.7118e-02, -4.9033e-02, -5.0447e-02,  ..., -4.2832e-02,\n",
       "           -4.3443e-02, -4.4054e-02],\n",
       "          [-4.8489e-02, -5.0458e-02, -5.1910e-02,  ..., -4.3833e-02,\n",
       "           -4.4466e-02, -4.5099e-02],\n",
       "          ...,\n",
       "          [-3.4225e-02, -3.5480e-02, -3.6235e-02,  ..., -3.6380e-03,\n",
       "           -4.5770e-03, -5.5159e-03],\n",
       "          [-3.4650e-02, -3.5923e-02, -3.6692e-02,  ..., -4.0176e-03,\n",
       "           -4.9554e-03, -5.8931e-03],\n",
       "          [-3.5075e-02, -3.6366e-02, -3.7150e-02,  ..., -4.3972e-03,\n",
       "           -5.3338e-03, -6.2704e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.4055e-02, -1.4669e-02, -1.5174e-02,  ..., -1.4934e-02,\n",
       "           -1.4735e-02, -1.4535e-02],\n",
       "          [-1.4670e-02, -1.5311e-02, -1.5840e-02,  ..., -1.5682e-02,\n",
       "           -1.5471e-02, -1.5260e-02],\n",
       "          [-1.5180e-02, -1.5844e-02, -1.6393e-02,  ..., -1.6411e-02,\n",
       "           -1.6188e-02, -1.5964e-02],\n",
       "          ...,\n",
       "          [-9.7077e-03, -1.0271e-02, -1.0900e-02,  ..., -3.6247e-02,\n",
       "           -3.5406e-02, -3.4566e-02],\n",
       "          [-9.7460e-03, -1.0310e-02, -1.0939e-02,  ..., -3.6253e-02,\n",
       "           -3.5424e-02, -3.4594e-02],\n",
       "          [-9.7843e-03, -1.0350e-02, -1.0979e-02,  ..., -3.6260e-02,\n",
       "           -3.5441e-02, -3.4623e-02]],\n",
       "\n",
       "         [[-6.7164e-03, -7.0116e-03, -7.2577e-03,  ..., -1.7474e-02,\n",
       "           -1.7473e-02, -1.7472e-02],\n",
       "          [-7.1299e-03, -7.4439e-03, -7.7063e-03,  ..., -1.8451e-02,\n",
       "           -1.8447e-02, -1.8443e-02],\n",
       "          [-7.6124e-03, -7.9489e-03, -8.2314e-03,  ..., -1.9509e-02,\n",
       "           -1.9499e-02, -1.9490e-02],\n",
       "          ...,\n",
       "          [-7.6108e-03, -8.0202e-03, -8.4487e-03,  ..., -1.5610e-02,\n",
       "           -1.4951e-02, -1.4292e-02],\n",
       "          [-6.0732e-03, -6.4115e-03, -6.7765e-03,  ..., -1.2417e-02,\n",
       "           -1.1767e-02, -1.1116e-02],\n",
       "          [-4.5356e-03, -4.8027e-03, -5.1043e-03,  ..., -9.2244e-03,\n",
       "           -8.5818e-03, -7.9393e-03]],\n",
       "\n",
       "         [[-1.5212e-02, -1.5916e-02, -1.6545e-02,  ..., -1.3147e-02,\n",
       "           -1.3056e-02, -1.2966e-02],\n",
       "          [-1.5881e-02, -1.6617e-02, -1.7274e-02,  ..., -1.3785e-02,\n",
       "           -1.3689e-02, -1.3592e-02],\n",
       "          [-1.6440e-02, -1.7202e-02, -1.7884e-02,  ..., -1.4387e-02,\n",
       "           -1.4284e-02, -1.4180e-02],\n",
       "          ...,\n",
       "          [-1.7114e-02, -1.8044e-02, -1.9028e-02,  ..., -3.4502e-02,\n",
       "           -3.3708e-02, -3.2913e-02],\n",
       "          [-1.7111e-02, -1.8041e-02, -1.9022e-02,  ..., -3.4297e-02,\n",
       "           -3.3501e-02, -3.2704e-02],\n",
       "          [-1.7109e-02, -1.8037e-02, -1.9016e-02,  ..., -3.4091e-02,\n",
       "           -3.3293e-02, -3.2495e-02]]]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 19, 256, 256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
